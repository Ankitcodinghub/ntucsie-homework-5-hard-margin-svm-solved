# ntucsie-homework-5-hard-margin-svm-solved
**TO GET THIS SOLUTION VISIT:** [NTUCSIE Homework 5-Hard-Margin SVM Solved](https://www.ankitcodinghub.com/product/ntucsie-homework-5-hard-margin-svm-solved/)


---

📩 **If you need this solution or have special requests:** **Email:** ankitcoding@gmail.com  
📱 **WhatsApp:** +1 419 877 7882  
📄 **Get a quote instantly using this form:** [Ask Homework Questions](https://www.ankitcodinghub.com/services/ask-homework-questions/)

*We deliver fast, professional, and affordable academic help.*

---

<h2>Description</h2>



<div class="kk-star-ratings kksr-auto kksr-align-center kksr-valign-top" data-payload="{&quot;align&quot;:&quot;center&quot;,&quot;id&quot;:&quot;93626&quot;,&quot;slug&quot;:&quot;default&quot;,&quot;valign&quot;:&quot;top&quot;,&quot;ignore&quot;:&quot;&quot;,&quot;reference&quot;:&quot;auto&quot;,&quot;class&quot;:&quot;&quot;,&quot;count&quot;:&quot;0&quot;,&quot;legendonly&quot;:&quot;&quot;,&quot;readonly&quot;:&quot;&quot;,&quot;score&quot;:&quot;0&quot;,&quot;starsonly&quot;:&quot;&quot;,&quot;best&quot;:&quot;5&quot;,&quot;gap&quot;:&quot;4&quot;,&quot;greet&quot;:&quot;Rate this product&quot;,&quot;legend&quot;:&quot;0\/5 - (0 votes)&quot;,&quot;size&quot;:&quot;24&quot;,&quot;title&quot;:&quot;NTUCSIE Homework 5-Hard-Margin SVM Solved&quot;,&quot;width&quot;:&quot;0&quot;,&quot;_legend&quot;:&quot;{score}\/{best} - ({count} {votes})&quot;,&quot;font_factor&quot;:&quot;1.25&quot;}">

<div class="kksr-stars">

<div class="kksr-stars-inactive">
            <div class="kksr-star" data-star="1" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="2" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="3" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="4" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="5" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
    </div>

<div class="kksr-stars-active" style="width: 0px;">
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
    </div>
</div>


<div class="kksr-legend" style="font-size: 19.2px;">
            <span class="kksr-muted">Rate this product</span>
    </div>
    </div>
<div class="page" title="Page 1">
<div class="layoutArea">
<div class="column">
Hard-Margin SVM

1. Consider N “linearly separable” 1D examples {(xn,yn)}Nn=1. That is, xn ∈ R. Without loss of generality, assume that x1 ≤ x2 ≤ …xM &lt; xM+1 ≤ xM+2 … ≤ xN, yn = −1 for n = 1,2,…,M, and yn = +1 for n = M + 1,M + 2,…,N. Which of the following represents a large-margin separating hyperplane? Choose the correct answer; explain your answer.

[a] w=1,b=−xM+1+xM 2

[b] w = −1, b = xM+1+xM 2

[c] w=1,b=−xM+1−xM 2

[d] w = −1, b = xM+1−xM 2

[e] none of the other choices

(Hint: The hard-margin SVM gets a specially-scaled version of the solution above.)

</div>
</div>
</div>
<div class="page" title="Page 2">
<div class="layoutArea">
<div class="column">
<ol start="2">
<li>Following the notations in the lecture for the hard-margin SVM in the Z-space. At the optimal (b,w) and α, how many of the following values are equal to the length of margin (the distance between the closest example and the decision boundary)? Choose the correct answer; explain why the values equal the margin in your chosen answer.(1) ∥w||−1/2

(2) 2∥w∥−1

(3) ∥w∥−1

(4) (􏰅Nn=1 αn)−1/2

(5) 􏰅Nn=1[αn = 1]

(6) (2 􏰅Nn=1 αn − ∥ 􏰅Nn=1 αnynzn∥2)−1/2

[a] 0 [b] 1 [c] 2 [d] 3 [e] 4
</li>
<li>Sometimes we hope to achieve a smaller margin for the positive examples, and a bigger margin for the negative ones. For instance, if we have very few negative examples on hand, we may hope to give them a larger margin to better protect them from noise. Consider an uneven-margin SVM that solves</li>
</ol>
</div>
</div>
<div class="layoutArea">
<div class="column">
w,b subject to

Consider the following examples

</div>
<div class="column">
2

􏰃wT xn + b􏰄 ≥ 1 for yn &gt; 0,

−􏰃wT xn + b􏰄 ≥ ρ− for yn &lt; 0.

</div>
</div>
<div class="layoutArea">
<div class="column">
min 1wTw

</div>
</div>
<div class="layoutArea">
<div class="column">
x1 =(0,1)

x2 =(0,0) x3 =(0,−1) x4 =(1,0)

</div>
<div class="column">
y1 =−1 y2 =−1 y3 =−1 y4 =+1

</div>
</div>
<div class="layoutArea">
<div class="column">
Take ρ− = 4. What is the optimal w and b? Choose the correct answer; explain your answer. (Note: You can calculate your answer with a QP solver if you want, but you need to “explain” the solution that was found. We suggest you to visualize what happens.)

[a] the optimal w = (1,0),b = −1 [b] the optimal w = (2,0),b = −1 [c] the optimal w = (5,0),b = −4 [d] the optimal w = (51,0),b = −4

[e] none of the other choices

</div>
</div>
</div>
<div class="page" title="Page 3">
<div class="layoutArea">
<div class="column">
4. The dual problem of the uneven-margin SVM defined in Problem 3 can be written as 1NN

</div>
</div>
<div class="layoutArea">
<div class="column">
What is □? Choose the correct answer; explain your answer. 􏰅N 􏰅N −1

</div>
</div>
<div class="layoutArea">
<div class="column">
[a] − n=1􏰉yn =+1􏰊αn − n=1ρ− 􏰉yn =−1􏰊αn

</div>
</div>
<div class="layoutArea">
<div class="column">
min 􏰆 􏰆 αnαmynymxTn xm + □

</div>
</div>
<div class="layoutArea">
<div class="column">
α2

n=1 m=1

</div>
</div>
<div class="layoutArea">
<div class="column">
N

subjectto 􏰆ynαn =0

n=1

αn ≥ 0 for n = 1,2,…,N.

</div>
</div>
<div class="layoutArea">
<div class="column">
􏰅N 􏰅N −1

[b] − n=1􏰉yn =+1􏰊αn + n=1ρ− 􏰉yn =−1􏰊αn

</div>
</div>
<div class="layoutArea">
<div class="column">
􏰅N

[c] − n=1􏰉yn =+1􏰊αn −

􏰅N

[d] − n=1􏰉yn =+1􏰊αn +

[e] none of the other choices

</div>
</div>
<div class="layoutArea">
<div class="column">
􏰅N

n=1ρ−􏰉yn =−1􏰊αn

n=1ρ−􏰉yn =−1􏰊αn

</div>
</div>
<div class="layoutArea">
<div class="column">
􏰅N

</div>
</div>
<div class="layoutArea">
<div class="column">
5. Let α∗ be an optimal solution of the original hard-margin SVM (i.e. even margin). Which of the following is an optimal solution of the uneven-margin SVM for a given ρ−? Choose the correct answer; explain your answer.

[a] α∗

[b] √ρ−α∗

[c] 2 α∗ 1+ρ−

[d] 1+ρ− α∗ 2

[e] none of the other choices Kernels

6. Kernels are able to embed high-dimensional feature spaces. Consider the homogeneous polynomial kernel with degree Q,

K(x, x′) = 􏰁xT x′􏰂Q ,

where each x and x′ is in Rd, without padding x0 = 1. Now, decompose K(x,x′) as some Φ(x)T Φ(x′), where Φ(x) includes unique terms calculated from x. That is, x3x5 would be con- sidered the same term as x5x3 (Note: this is different from the Φ(x) that we considered in class). What is dimension of Φ(x)? Choose the correct answer; explain your answer.

</div>
</div>
<div class="layoutArea">
<div class="column">
[a] [b] [c]

[d] [e]

</div>
<div class="column">
􏰌Q+d−1􏰍 Q

􏰌Q+d−1􏰍 d

􏰌Q+d􏰍 Q

􏰌Q+d􏰍 d

none of the other choices

</div>
</div>
</div>
<div class="page" title="Page 4">
<div class="layoutArea">
<div class="column">
7. For any feature transform Φ from X to Z, the squared distance between two examples x and x′ is ∥Φ(x) − Φ(x′)∥2 in the Z-space. The distance can be computed with the kernel trick. Consider the degree-2 quadratic kernel K2(x, x′) = (1 + xT x′)2. What is the tightest upper bound for the squared distance between two unit vectors x and x′ in the Z-space? Choose the correct answer; explain your answer.

[a] 0 [b] 1 [c] 2 [d] 8

[e] 1126

Kernel Perceptron Learning Algorithm

8. In this problem, we are going to apply the kernel trick to the perceptron learning algorithm. If we run the perceptron learning algorithm on the transformed examples {(φ(xn),yn)}Nn=1, the

􏰃􏰄

algorithm updates wt to wt+1 when the current wt makes a mistake on φ(xn(t)),yn(t) : wt+1 ← wt + yn(t)φ(xn(t))

Because every update is based on one (transformed) example, if we take w0 = 0, we can represent every wt as a linear combination of {φ(xn)}Nn=1. We can then maintain the linear combination coefficients instead of the whole w. Assume that we maintain an N-dimensional vector αt in the t-th iteration such that

N

wt = 􏰆 αt[n]φ(xn)

n=1

for t = 0, 1, 2, . . ., where αt[n] indicates the n-th component of αt. Set α0 = 0 (N zeros) to match

w0 = 0 (d ̃+ 1 zeros). What should αt+1[n(t)] be when the current wt (represented by αt) makes

</div>
</div>
<div class="layoutArea">
<div class="column">
􏰃􏰄

a mistake on φ(xn(t)),yn(t)

<ol>
<li>[a] &nbsp;αt [n(t)] +1</li>
<li>[b] &nbsp;αt [n(t)] −1</li>
<li>[c] &nbsp;αt [n(t)] + yn(t)</li>
<li>[d] &nbsp;αt [n(t)] − yn(t)</li>
<li>[e] &nbsp;none of the other choices</li>
</ol>
</div>
</div>
<div class="layoutArea">
<div class="column">
? Choose the correct answer; explain your answer.

</div>
</div>
</div>
<div class="page" title="Page 5">
<div class="layoutArea">
<div class="column">
Soft-Margin SVM

9. Suppose we want to emphasize that some training examples are more important than others. For- mally, consider a data set D = {(xn, yn, un)}Nn=1, where un is a non-negative weight that indicates the importance of the n-th example. The soft-margin SVM with this weighted classification problem solves the following constrained optimization problem:

min

w,b,ξ subjectto

</div>
</div>
<div class="layoutArea">
<div class="column">
1T 􏰆N

</div>
</div>
<div class="layoutArea">
<div class="column">
un·ξn nnn

</div>
</div>
<div class="layoutArea">
<div class="column">
w w+

y 􏰃wTΦ(x )+b􏰄≥1−ξ

</div>
</div>
<div class="layoutArea">
<div class="column">
2

</div>
<div class="column">
n=1

</div>
</div>
<div class="layoutArea">
<div class="column">
ξn≥0, n=1,…,N.

We can then derive the dual version of the weighted soft-margin SVM problem that involves only

</div>
</div>
<div class="layoutArea">
<div class="column">
α, y, X, and u:

</div>
</div>
<div class="layoutArea">
<div class="column">
min ♢ α

N

subjectto 􏰆ynαn =0

n=1

0≤αn ≤un, forn=1,2,···,N

</div>
</div>
<div class="layoutArea">
<div class="column">
Which of the following is the correct form of ♢? Choose the correct answer; explain your answer.

<ol>
<li>[a] &nbsp;21 􏰅Nn=1 􏰅Nm=1 αnαmynymΦ(xn)T Φ(xm) − 􏰅Nn=1 αn</li>
<li>[b] &nbsp;21 􏰅Nn=1 􏰅Nm=1 αnαmynymunumΦ(xn)T Φ(xm) − 􏰅Nn=1 αn</li>
<li>[c] &nbsp;21 􏰅Nn=1 􏰅Nm=1 αnαmynymunumΦ(xn)T Φ(xm) − 􏰅Nn=1 unαn2 n=1 m=1</li>
</ol>
[e] none of the other choices

10. As discussed in class, the primal optimization problem for the soft-margin SVM is equivalent to the following unconstrained optimization problem.

</div>
</div>
<div class="layoutArea">
<div class="column">
[d] 1􏰅N 􏰅N αnαmynymΦ(xn)T Φ(xm) − 􏰅N unαn

</div>
</div>
<div class="layoutArea">
<div class="column">
1 􏰆N min wTw+C

n=1

Letsn =wTxn+bandρn =yn·sn. TheerrorfunctionEhinge(ρ)=max(1−ρ,0)iswidelyknown as the hinge error. The hinge error is convex but is not differentiable everywhere. Therefore, it can be technically complicated to run gradient descent on the error. A possible workaround is to approximate the hinge error with a “smooth hinge error.” A good candidate of “smooth hinge error” is the following function

</div>
</div>
<div class="layoutArea">
<div class="column">
b,w 2

</div>
<div class="column">
max(1−yn(wTxn +b),0)

</div>
</div>
<div class="layoutArea">
<div class="column">
 0 Esmooth(ρ) = 1(1−ρ)2

2

 0 . 5 − ρ

</div>
<div class="column">
ρ ≥ 1

0 &lt; ρ &lt; 1 ρ ≤ 0

</div>
</div>
<div class="layoutArea">
<div class="column">
Since Esmooth is differentiable everywhere, we can then apply gradient descent and related algo- rithms. Esmooth has a constant slope of −1 for all ρ ≤ 0 and is 0 for all ρ ≥ 1, just like Ehinge. Now, within (0, 1), what is the uniformly-averaged squared difference between Esmooth and Ehinge? Choose the correct answer; explain your answer.

[a] 1 15

[b] 1 24

[c] 1 30

[d] ∞

[e] none of the other choices

</div>
</div>
<div class="layoutArea">
<div class="column">
5 of 7

</div>
</div>
<div class="layoutArea">
<div class="column">
n=1

</div>
</div>
</div>
<div class="page" title="Page 6">
<div class="layoutArea">
<div class="column">
Experiments with Soft-Margin SVM

For Problems 11 to 16, we are going to experiment with a real-world data set. Download the processed satimage data sets from LIBSVM Tools.

Training: https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/satimage.scale

Testing: https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/satimage.scale.t

We will consider binary classification problems of the form “one of the classes” (as the positive class) versus “the other classes” (as the negative class).

The data set contains thousands of examples, and some quadratic programming packages cannot handle this size. We recommend that you consider the LIBSVM package

<pre>                       http://www.csie.ntu.edu.tw/~cjlin/libsvm/
</pre>
Regardless of the package that you choose to use, please read the manual of the package carefully to make sure that you are indeed solving the soft-margin support vector machine taught in class like the dual formulation below:

1NN N min 􏰆 􏰆 αnαmynymK(xn, xm) − 􏰆 αn

n=1

</div>
</div>
<div class="layoutArea">
<div class="column">
α2

</div>
</div>
<div class="layoutArea">
<div class="column">
n=1 m=1 N

subjectto 􏰆 ynαn = 0 n=1

</div>
</div>
<div class="layoutArea">
<div class="column">
0≤αn ≤C

In the following problems, please use the 0/1 error for evaluating Ein, Eval and Eout (through the test

set). Some practical remarks include

<ol>
<li>(i) &nbsp;Please tell your chosen package to not automatically scale the data for you, lest you should change the effective kernel and get different results.</li>
<li>(ii) &nbsp;It is your responsibility to check whether your chosen package solves the designated formulation with enough numerical precision. Please read the manual of your chosen package for software parameters whose values affect the outcome—any ML practitioner needs to deal with this kind of added uncertainty.</li>
</ol>
11. (*) Consider the linear soft-margin SVM. That is, either solve the primal formulation of soft-margin SVM with the given xn, or take the linear kernel K(xn, xm) = xTn xm in the dual formulation. With C = 10, and the binary classification problem of “5” versus “not 5”, which of the following numbers is closest to ∥w∥ after solving the linear soft-margin SVM? Choose the closest answer; provide your command/code.

[a] 4.5 [b] 5.0 [c] 5.5 [d] 6.0 [e] 6.5

</div>
</div>
<div class="layoutArea">
<div class="column">
6 of 7

</div>
</div>
<div class="layoutArea">
<div class="column">
n=1,…,N.

</div>
</div>
</div>
<div class="page" title="Page 7">
<div class="layoutArea">
<div class="column">
<ol start="12">
<li>(*) Consider the polynomial kernel K(xn, xm) = (1 + xTn xm)Q, where Q is the degree of the polynomial. With C = 10, Q = 3, which of the following soft-margin SVM classifiers reaches the largest Ein? Choose the correct answer; provide your command/code.[a] “2” versus “not 2” [b] “3” versus “not 3” [c] “4” versus “not 4” [d] “5” versus “not 5” [e] “6” versus “not 6”</li>
<li>(*) Following Problem 12, which of the following numbers is closest to the maximum number of support vectors within those five soft-margin SVM classifiers? Choose the closest answer; provide your command/code.[a] 450 [b] 500 [c] 550 [d] 600 [e] 650</li>
<li>(*) Consider the Gaussian kernel K(xn, xm) = exp 􏰁−γ||xn − xm||2􏰂. For the binary classification problem of “1” versus “not 1”, when fixing γ = 10, which of the following values of C results in the lowest Eout? If there is a tie, please pick the smallest C. Choose the correct answer; provide your command/code.[a] 0.01 [b] 0.1
[c] 1 [d] 10

[e] 100
</li>
<li>(*) Following Problem 14, when fixing C = 0.1, which of the following values of γ results in the lowest Eout? If there is a tie, please pick the smallest γ. Choose the correct answer; provide your command/code.[a] 0.1 [b] 1
[c] 10 [d] 100

[e] 1000
</li>
<li>(*) Following Problem 14 and consider a validation procedure that randomly samples 200 examplesfrom the training set for validation and leaves the other examples for training g− . Fix C = 0.1 svm
and use the validation procedure to choose the best γ among {0.1,1,10,100,1000} according to Eval. If there is a tie of Eval, choose the smallest γ. Repeat the procedure 1000 times. Which of the following values of γ is selected the most number of times? Choose the correct answer; provide your command/code.

[a] 0.1 [b] 1

[c] 10 [d] 100

[e] 1000
</li>
</ol>
</div>
</div>
<div class="layoutArea">
<div class="column">
7 of 7

</div>
</div>
</div>
